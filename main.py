# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/168LG-9-PiXQkSRVVRJGDlFlHg_hRxerY

Importo las librerias que voy a usar
"""

import numpy as np
from sklearn import datasets
from sklearn.linear_model import LinearRegression
import pandas as pd
import seaborn as sns
import tensorflow as tf
import pathlib
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.keras import layers
import datetime as dt

"""Utilizo la libreria :pandas para comvertir el csv en un dataframe y combierto el campo Date a un formato legible para la reguesion lineal"""

train = pd.read_csv('train.csv', sep = ',')

train['Date'] = pd.to_datetime(train['Date'])
train['Date']=train['Date'].map(dt.datetime.toordinal)

"""Visualizo el dataframe para ver que todo esta bien"""

train.head(100)

"""Realizo un conteo de todos los tatos y cuantos nulos tengo para valorar mi sigueinte paso."""

train.count()

train.isnull().sum()

"""Podemos observar que se han detectado 133 filas completamente vacias a falta de fecha y target, por lo tanto se deben eliminar todos esos datos que pueden sesgar nuestro modelo."""

train = train.dropna()

"""Comprobamos si se han eliminado todos los nulos"""

train.isnull().sum()

"""Ahora ya tenemos el dataframe perfecto para crear un modelo predictivo supervisado.

Primero nos quedaremos con un 80% del total de datos elegidos aleatoriamente para realizar el modelo y  el 20% restante sera para ver como de bien o mal realiza las prediciones.
"""

trainSplit = train.sample(frac=0.8,random_state=0)
test = train.drop(trainSplit.index)

"""Ahora vamos a visualizar unos graficos para entender mejor el dataset y observar que tipo de modelo es el mas optimo."""

sns.pairplot(trainSplit[["Open", "High", "Low", "Close", "Adj Close", "Volume"]], diag_kind="kde")

"""Separamos el target del resto de variables"""

train_labels = trainSplit.pop('Target')
test_labels = test.pop('Target')

"""definimos la funcion encargada de la creacion del modelo"""

def build_model():
  model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=[len(trainSplit.keys())]),
    layers.Dense(64, activation='relu'),
    layers.Dense(1)
  ])

  optimizer = tf.keras.optimizers.RMSprop(0.001)

  model.compile(loss='mse',
                optimizer=optimizer,
                metrics=['mae', 'mse'])
  return model

model = build_model()

model.summary()

class PrintDot(keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs):
    if epoch % 100 == 0: print('')
    print('.', end='')

EPOCHS = 1000

history = model.fit(
  trainSplit, train_labels,
  epochs=EPOCHS, validation_split = 0.2, verbose=0,
  callbacks=[PrintDot()])

hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch
hist.tail()

def plot_history(history):
  hist = pd.DataFrame(history.history)
  hist['epoch'] = history.epoch

  plt.figure()
  plt.xlabel('Epoch')
  plt.ylabel('Mean Abs Error [MPG]')
  plt.plot(hist['epoch'], hist['mae'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_mae'],
           label = 'Val Error')
  plt.ylim([0,5])
  plt.legend()

  plt.figure()
  plt.xlabel('Epoch')
  plt.ylabel('Mean Square Error [$MPG^2$]')
  plt.plot(hist['epoch'], hist['mse'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_mse'],
           label = 'Val Error')
  plt.ylim([0,20])
  plt.legend()
  plt.show()


plot_history(history)

model = build_model()

# The patience parameter is the amount of epochs to check for improvement
early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)

history = model.fit(trainSplit, train_labels, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(history)
